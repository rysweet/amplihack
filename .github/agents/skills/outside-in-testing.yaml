# GitHub Copilot CLI Custom Agent
# Generated from amplihack skill: /home/azureuser/src/amplihack/.claude/skills/outside-in-testing/SKILL.md

name: outside-in-testing
description: |
  |

model: claude-sonnet-4.5

tools:
  []

activation_keywords:
  []

instructions: |
  # Outside-In Testing Skill
  
  ## Purpose [LEVEL 1]
  
  This skill helps you create **agentic outside-in tests** that verify application behavior from an external user's perspective without any knowledge of internal implementation. Using the gadugi-agentic-test framework, you write declarative YAML scenarios that AI agents execute, observe, and validate.
  
  **Key Principle**: Tests describe WHAT should happen, not HOW it's implemented. Agents figure out the execution details.
  
  ## When to Use This Skill [LEVEL 1]
  
  ### Perfect For
  
  - **Smoke Tests**: Quick validation that critical user flows work
  - **Behavior-Driven Testing**: Verify features from user perspective
  - **Cross-Platform Testing**: Same test logic for CLI, TUI, Web, Electron
  - **Refactoring Safety**: Tests remain valid when implementation changes
  - **AI-Powered Testing**: Let agents handle complex interactions
  - **Documentation as Tests**: YAML scenarios double as executable specs
  
  ### Use This Skill When
  
  - Starting a new project and defining expected behaviors
  - Refactoring code and need tests that won't break with internal changes
  - Testing user-facing applications (CLI tools, TUIs, web apps, desktop apps)
  - Writing acceptance criteria that can be automatically verified
  - Need tests that non-developers can read and understand
  - Want to catch regressions in critical user workflows
  - Testing complex multi-step interactions
  
  ### Don't Use This Skill When
  
  - Need unit tests for internal functions (use test-gap-analyzer instead)
  - Testing performance or load characteristics
  - Need precise timing or concurrency control
  - Testing non-interactive batch processes
  - Implementation details matter more than behavior
  
  ## Core Concepts [LEVEL 1]
  
  ### Outside-In Testing Philosophy
  
  **Traditional Inside-Out Testing**:
  
  ```python
  # Tightly coupled to implementation
  def test_calculator_add():
      calc = Calculator()
      result = calc.add(2, 3)
      assert result == 5
      assert calc.history == [(2, 3, 5)]  # Knows internal state
  ```
  
  **Agentic Outside-In Testing**:
  
  ```yaml
  # Implementation-agnostic behavior verification
  scenario:
    name: "Calculator Addition"
    steps:
      - action: launch
        target: "./calculator"
      - action: send_input
        value: "add 2 3"
      - action: verify_output
        contains: "Result: 5"
  ```
  
  **Benefits**:
  
  - Tests survive refactoring (internal changes don't break tests)
  - Readable by non-developers (YAML is declarative)
  - Platform-agnostic (same structure for CLI/TUI/Web/Electron)
  - AI agents handle complexity (navigation, timing, screenshots)
  
  ### The Gadugi Agentic Test Framework [LEVEL 2]
  
  Gadugi-agentic-test is a Python framework that:
  
  1. **Parses YAML test scenarios** with declarative steps
  2. **Dispatches to specialized agents** (CLI, TUI, Web, Electron agents)
  3. **Executes actions** (launch, input, click, wait, verify)
  4. **Collects evidence** (screenshots, logs, output captures)
  5. **Validates outcomes** against expected results
  6. **Generates reports** with evidence trails
  
  **Architecture**:
  
  ```
  YAML Scenario → Scenario Loader → Agent Dispatcher → Execution Engine
                                            ↓
                       [CLI Agent, TUI Agent, Web Agent, Electron Agent]
                                            ↓
                             Observers → Comprehension Agent
                                            ↓
                                     Evidence Report
  ```
  
  ### Progressive Disclosure Levels [LEVEL 1]
  
  This skill teaches testing in three levels:

# Source: /home/azureuser/src/amplihack/.claude/skills/outside-in-testing/SKILL.md
