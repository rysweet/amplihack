---
name: Documentation Noob Tester
description: Automatically review documentation from a beginner's perspective to identify confusing or unclear sections and suggest improvements
on:
  schedule:
    - cron: "0 9 * * 1" # Weekly on Monday at 9 AM UTC
  workflow_dispatch:
permissions:
  contents: read
safe-outputs:
  create-issue:
    max: 10
  add-comment:
    max: 5
tools:
  github:
    toolsets: [default]
  bash: true
timeout-minutes: 30
strict: true
---

# Documentation Noob Tester Workflow

**Purpose**: Automatically review documentation from a beginner's perspective to identify confusing or unclear sections and suggest improvements.

## Schedule

- **Weekly execution**: Every Monday at 9:00 AM UTC
- **Manual trigger**: `workflow_dispatch` available

## Permissions

```yaml
permissions:
  contents: read
  issues: write
```

Write operations are controlled via safe-outputs:

```yaml
safe-outputs:
  create-issue:
    max: 10
  add-label:
    max: 10
  add-comment:
    max: 5
```

## Configuration

### Timeouts

- **Workflow timeout**: 30 minutes

### Engine Settings

- **Copilot mode**: strict
- **Toolsets**: github, bash, jq, file-operations

## Testing Perspective

The workflow simulates a **complete beginner** who:

- Has never seen the project before
- Lacks domain expertise
- Needs clear, step-by-step guidance
- Questions unclear assumptions
- Identifies missing prerequisites

## Documentation Scope

### Target Documents

Priority documents to test (in order):

1. **README.md** (root)
2. **CONTRIBUTING.md**
3. **docs/getting-started/**
4. **docs/tutorials/**
5. **.claude/context/** (for AI agent documentation)
6. **API documentation**
7. **Workflow documentation** (.github/workflows/\*.md)

### Evaluation Criteria

For each document section, evaluate:

1. **Clarity**: Is the language simple and unambiguous?
2. **Completeness**: Are all necessary steps included?
3. **Prerequisites**: Are requirements explicitly stated?
4. **Examples**: Are concrete examples provided?
5. **Navigation**: Can readers find related information easily?
6. **Accessibility**: Is technical jargon explained?

## Testing Methodology

### Phase 1: Document Discovery

1. **Scan repository** for documentation files
2. **Prioritize** based on target list above
3. **Track** previously tested documents to avoid duplication

### Phase 2: Beginner Simulation

For each document:

1. **Read as a beginner** - Assume no prior knowledge
2. **Follow instructions literally** - Try each step exactly as written
3. **Note confusion points** - Where would a beginner get stuck?
4. **Identify gaps** - What critical information is missing?
5. **Check assumptions** - What knowledge is assumed but not stated?

### Phase 3: Issue Creation

Create GitHub issues for:

- **Critical gaps**: Missing prerequisites, broken links, incorrect commands
- **Confusing sections**: Unclear explanations, undefined jargon
- **Improvement opportunities**: Missing examples, poor organization

## Issue Template

```markdown
## ðŸ“š Documentation Improvement Needed

**Document**: [file path]
**Section**: [section heading or line range]
**Issue Type**: [Critical Gap | Confusing Section | Improvement Opportunity]

### Problem from Beginner Perspective

[Describe what's confusing or missing when reading as a complete beginner]

### Specific Examples

[Quote the problematic text or describe the missing content]

### Suggested Improvements

- [ ] [Specific actionable suggestion 1]
- [ ] [Specific actionable suggestion 2]
- [ ] [Specific actionable suggestion 3]

### Context

- **Assumed Knowledge**: [What knowledge is assumed but not explained?]
- **Missing Prerequisites**: [What should be installed/configured first?]
- **Related Docs**: [Links to related documentation]

---

_Generated by docs-noob-tester workflow on [date]_
_This workflow simulates a complete beginner reviewing our documentation_
```

## Workflow Steps

### 1. Initialize Testing Session

- Identify documentation files to test
- Load previously tested document history
- Prioritize based on last update date and test date

### 2. Simulate Beginner Review

For each priority document:

- Read document section by section
- Apply beginner evaluation criteria
- Document confusion points and gaps
- Rate severity (critical, important, nice-to-have)

### 3. Generate Issue Reports

- Create issues for findings above threshold
- Apply appropriate labels:
  - `documentation`
  - `good-first-issue` (for simple fixes)
  - `help-wanted` (for more complex improvements)
  - `accessibility` (for jargon/clarity issues)
- Avoid duplicate issues (check existing open issues)

### 4. Create Summary Report

Generate workflow summary with:

- Documents tested
- Issues created (with links)
- Most common problems identified
- Recommendations for documentation priorities

### 5. Update Testing History

- Record documents tested and dates
- Track issue creation to avoid duplicates
- Note documents that need retesting after updates

## Quality Guidelines

### Issue Creation Best Practices

1. **Be specific**: Quote exact text or line numbers
2. **Be actionable**: Provide clear improvement suggestions
3. **Be empathetic**: Frame feedback constructively
4. **Be realistic**: Focus on high-impact improvements

### Avoiding Issue Spam

- **Batch related issues**: Group related problems in one issue
- **Threshold for creation**: Only create issues for significant problems
- **Check for duplicates**: Search existing issues first
- **Respect safe-output limits**: Maximum 10 issues per run

### Communication Tone

All issues should:

- Acknowledge the effort in existing documentation
- Frame issues as opportunities for improvement
- Provide specific, actionable suggestions
- Encourage collaboration ("Would it help to...", "Consider adding...")

## Example Findings

### Critical Gap Example

```
**Document**: README.md
**Section**: Installation

**Problem**: Instructions say "Install dependencies with `make install`"
but don't mention that `make` itself needs to be installed first.

**Suggestion**: Add prerequisite section:

- macOS: `brew install make`
- Ubuntu/Debian: `sudo apt-get install build-essential`
- Windows: Install WSL first (link to guide)
```

### Confusing Section Example

````
**Document**: CONTRIBUTING.md
**Section**: Running Tests

**Problem**: Says "Run the test suite" without explaining which command,
where to run it, or what output to expect.

**Suggestion**: Replace with:

```bash
# From the project root directory, run:
pytest

# Expected output:
# ===== test session starts =====
# collected 42 items
# ...
```
````

### Improvement Opportunity Example

```
**Document**: docs/api-reference.md
**Section**: Authentication

**Problem**: Uses technical terms like "JWT bearer token" without
explanation. Beginners may not know what these are.

**Suggestion**: Add brief explainer:
"JWT (JSON Web Token) bearer tokens are like digital ID cards..."
Or link to external resource: [What is JWT?](...)
```

## Success Metrics

Track these metrics over time:

- **Issues created** per run
- **Issues resolved** (documentation improvements merged)
- **Time to resolution** for documentation issues
- **User feedback** on documentation quality
- **Reduction in support requests** (fewer questions about basics)

## Notes

- This workflow **complements** (not replaces) human documentation review
- Focus is on **beginner experience**, not technical accuracy
- Issues created are **suggestions**, not mandates
- Regular testing helps catch documentation drift
- Encourages **continuous documentation improvement**

## Future Enhancements

Potential improvements to consider:

- **Difficulty scoring**: Rate documentation complexity automatically
- **Link validation**: Check all links are functional
- **Screenshot checking**: Verify screenshots are up-to-date
- **Code example testing**: Run code examples to ensure they work
- **Readability metrics**: Calculate reading level scores
- **Internationalization**: Flag sections that need translation
