# Agent Integration Design: Neo4j Memory System

**Status**: Design Specification
**Date**: 2025-11-03
**Author**: Architect Agent
**Context**: Memory system is built (phases 1-6), but agents don't use it yet

---

## Executive Summary

This design bridges the **built Neo4j memory system** with **existing amplihack agents** through non-invasive hook integration. Agents automatically gain memory capabilities without requiring modifications to their markdown definitions.

**Key Insight**: Amplihack already has a sophisticated hook system (`session_start.py`, `stop.py`, `post_tool_use.py`). We extend this pattern with **memory-aware hooks** that inject context before agent execution and extract learnings after completion.

---

## 1. Architecture Overview

### 1.1 Integration Points

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Claude Code Session                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  SessionStart Hook                                           â”‚
â”‚  â”œâ”€ Load User Preferences âœ“ (existing)                      â”‚
â”‚  â”œâ”€ Load Original Request âœ“ (existing)                      â”‚
â”‚  â””â”€ Load Memory Context âš¡ (NEW)                             â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚         Agent Invocation (via Task)            â”‚          â”‚
â”‚  â”‚                                                 â”‚          â”‚
â”‚  â”‚  Pre-Agent Hook âš¡ (NEW)                        â”‚          â”‚
â”‚  â”‚  â”œâ”€ Detect agent type (architect, builder...) â”‚          â”‚
â”‚  â”‚  â”œâ”€ Query Neo4j for relevant memories         â”‚          â”‚
â”‚  â”‚  â”œâ”€ Format memory context                      â”‚          â”‚
â”‚  â”‚  â””â”€ Inject into agent prompt                   â”‚          â”‚
â”‚  â”‚                                                 â”‚          â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚          â”‚
â”‚  â”‚  â”‚   Agent Executes               â”‚           â”‚          â”‚
â”‚  â”‚  â”‚   (with memory context)        â”‚           â”‚          â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚          â”‚
â”‚  â”‚                                                 â”‚          â”‚
â”‚  â”‚  Post-Agent Hook âš¡ (NEW)                       â”‚          â”‚
â”‚  â”‚  â”œâ”€ Parse agent output                         â”‚          â”‚
â”‚  â”‚  â”œâ”€ Extract decisions & learnings              â”‚          â”‚
â”‚  â”‚  â”œâ”€ Assess quality                             â”‚          â”‚
â”‚  â”‚  â””â”€ Store in Neo4j                             â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                               â”‚
â”‚  Stop Hook                                                    â”‚
â”‚  â”œâ”€ Check lock flag âœ“ (existing)                            â”‚
â”‚  â”œâ”€ Trigger reflection âœ“ (existing)                         â”‚
â”‚  â””â”€ Consolidate session memories âš¡ (NEW)                    â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Legend:
âœ“ = Already implemented
âš¡ = New memory integration
```

### 1.2 Hook Lifecycle

```
Session Start
    â†“
[Memory: Load session-level context]
    â†“
Agent Invoked (Task tool)
    â†“
[Pre-Agent Hook: Query memories, inject context]
    â†“
Agent Executes
    â†“
[Post-Agent Hook: Extract & store learnings]
    â†“
Session End
    â†“
[Stop Hook: Consolidate & index memories]
```

---

## 2. Implementation Specifications

### 2.1 Pre-Agent Hook: Memory Loading

**Purpose**: Inject relevant memory context into agent prompts

**Location**: `~/.amplihack/.claude/tools/amplihack/hooks/pre_agent.py` (NEW)

**Trigger**: Before agent markdown file is loaded and prompt constructed

**Implementation**:

```python
#!/usr/bin/env python3
"""
Pre-agent hook for memory context injection.
Extends HookProcessor pattern used by session_start.py and stop.py.
"""

import sys
from pathlib import Path
from typing import Any, Dict, List, Optional

sys.path.insert(0, str(Path(__file__).parent))
from hook_processor import HookProcessor

# Import memory system
from amplihack.memory.neo4j.agent_memory import AgentMemoryManager
from amplihack.memory.neo4j.lifecycle import ensure_neo4j_running


class PreAgentHook(HookProcessor):
    """Hook processor for pre-agent memory injection."""

    # Map agent filenames to agent types
    AGENT_TYPE_MAP = {
        "architect.md": "architect",
        "builder.md": "builder",
        "reviewer.md": "reviewer",
        "tester.md": "tester",
        "optimizer.md": "optimizer",
        "security.md": "security",
        "database.md": "database",
        "api-designer.md": "api-designer",
        "integration.md": "integration",
        "analyzer.md": "analyzer",
        "cleanup.md": "cleanup",
        "fix-agent.md": "fix-agent",
        "pre-commit-diagnostic.md": "pre-commit-diagnostic",
        "ci-diagnostic.md": "ci-diagnostic",
    }

    def __init__(self):
        super().__init__("pre_agent")
        self.memory_enabled = self._check_memory_enabled()

    def _check_memory_enabled(self) -> bool:
        """Check if memory system is enabled."""
        config_file = self.project_root / ".claude" / "runtime" / "memory" / ".config"
        if not config_file.exists():
            return False

        import json
        try:
            with open(config_file) as f:
                config = json.load(f)
            return config.get("enabled", False)
        except Exception:
            return False

    def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Load and inject memory context for agent.

        Args:
            input_data: {
                "agent_file": "architect.md",
                "task": "Design authentication system",
                "task_category": "system_design",  # optional
                "session_id": "auto_claude_123456"
            }

        Returns:
            {
                "memory_context": "## Memory Context\n...",
                "metadata": {"memories_loaded": 5, ...}
            }
        """
        if not self.memory_enabled:
            self.log("Memory system disabled", "DEBUG")
            return {}

        # Extract agent type from filename
        agent_file = input_data.get("agent_file", "")
        agent_type = self.AGENT_TYPE_MAP.get(agent_file)

        if not agent_type:
            self.log(f"Unknown agent file: {agent_file}", "DEBUG")
            return {}

        # Extract task info
        task = input_data.get("task", "")
        task_category = input_data.get("task_category")

        # Query memories
        try:
            memory_context = self._query_memories(
                agent_type=agent_type,
                task=task,
                task_category=task_category
            )

            if memory_context:
                self.log(f"Loaded {len(memory_context['memories'])} memories for {agent_type}")
                self.save_metric("memories_loaded", len(memory_context["memories"]))

                return {
                    "memory_context": self._format_memory_context(memory_context),
                    "metadata": {
                        "memories_loaded": len(memory_context["memories"]),
                        "agent_type": agent_type
                    }
                }
            else:
                self.log(f"No relevant memories found for {agent_type}", "DEBUG")
                return {}

        except Exception as e:
            self.log(f"Memory query failed: {e}", "ERROR")
            # Non-fatal: agent continues without memory context
            return {}

    def _query_memories(
        self,
        agent_type: str,
        task: str,
        task_category: Optional[str] = None
    ) -> Dict[str, Any]:
        """Query Neo4j for relevant memories."""
        try:
            # Ensure Neo4j is running
            ensure_neo4j_running(blocking=False)

            # Create memory manager for this agent type
            mgr = AgentMemoryManager(agent_type=agent_type)

            # Detect task category if not provided
            if not task_category:
                task_category = self._detect_task_category(task)

            # Query memories
            memories = mgr.recall(
                category=task_category,
                min_quality=0.6,
                include_global=True,
                limit=10
            )

            # Also query cross-agent learnings if relevant
            cross_agent_memories = []
            if agent_type in ["architect", "builder"]:
                # These agents benefit from other agents' learnings
                cross_agent_memories = mgr.learn_from_others(
                    task_category=task_category,
                    min_quality=0.7,
                    limit=5
                )

            return {
                "memories": memories,
                "cross_agent_memories": cross_agent_memories,
                "agent_type": agent_type,
                "task_category": task_category
            }

        except Exception as e:
            self.log(f"Neo4j query error: {e}", "ERROR")
            return {}

    def _detect_task_category(self, task: str) -> str:
        """Simple keyword-based task category detection."""
        task_lower = task.lower()

        # Category keyword mapping
        categories = {
            "system_design": ["design", "architect", "structure", "pattern"],
            "implementation": ["implement", "build", "create", "code"],
            "error_handling": ["error", "exception", "fix", "bug"],
            "optimization": ["optimize", "performance", "speed", "efficiency"],
            "testing": ["test", "verify", "validate", "check"],
            "security": ["security", "auth", "permission", "vulnerability"],
            "database": ["database", "schema", "query", "migration"],
            "api": ["api", "endpoint", "route", "interface"],
        }

        for category, keywords in categories.items():
            if any(kw in task_lower for kw in keywords):
                return category

        return "general"

    def _format_memory_context(self, memory_data: Dict[str, Any]) -> str:
        """Format memory data for injection into agent prompt."""
        lines = ["## ðŸ§  Memory Context (Relevant Past Learnings)", ""]

        memories = memory_data.get("memories", [])
        cross_agent = memory_data.get("cross_agent_memories", [])
        agent_type = memory_data.get("agent_type", "unknown")

        if memories:
            lines.append(f"### Past {agent_type.title()} Agent Learnings")
            lines.append("")

            for i, mem in enumerate(memories[:5], 1):  # Top 5
                lines.append(f"**{i}. {mem.get('category', 'General')}** "
                           f"(quality: {mem.get('quality_score', 0):.2f})")
                lines.append(f"   {mem.get('content', '')}")

                if mem.get('metadata', {}).get('outcome'):
                    lines.append(f"   *Outcome: {mem['metadata']['outcome']}*")
                lines.append("")

        if cross_agent:
            lines.append(f"### Learnings from Other Agents")
            lines.append("")

            for i, mem in enumerate(cross_agent[:3], 1):  # Top 3
                other_agent = mem.get('agent_type', 'unknown')
                lines.append(f"**{i}. From {other_agent}**: {mem.get('category', '')}")
                lines.append(f"   {mem.get('content', '')}")
                lines.append("")

        if not memories and not cross_agent:
            lines.append("*No relevant past learnings found for this task.*")
            lines.append("")

        lines.append("---")
        lines.append("")

        return "\n".join(lines)


def main():
    """Entry point for pre-agent hook."""
    hook = PreAgentHook()
    hook.run()


if __name__ == "__main__":
    main()
```

**Key Features**:

- Non-invasive: Agents unaware of memory system
- Opt-in: Controlled via `~/.amplihack/.claude/runtime/memory/.config`
- Fast: Query limits prevent prompt bloat
- Intelligent: Task category detection + quality filtering
- Cross-agent learning: Architects see builder patterns, etc.

---

### 2.2 Post-Agent Hook: Memory Extraction

**Purpose**: Extract learnings from agent output and store in Neo4j

**Location**: `~/.amplihack/.claude/tools/amplihack/hooks/post_agent.py` (NEW)

**Trigger**: After agent completes, before returning to orchestrator

**Implementation**:

```python
#!/usr/bin/env python3
"""
Post-agent hook for memory extraction and storage.
Extends HookProcessor pattern for consistency.
"""

import sys
from pathlib import Path
from typing import Any, Dict, List, Optional
import re

sys.path.insert(0, str(Path(__file__).parent))
from hook_processor import HookProcessor

from amplihack.memory.neo4j.agent_memory import AgentMemoryManager
from amplihack.memory.neo4j.lifecycle import ensure_neo4j_running


class PostAgentHook(HookProcessor):
    """Hook processor for post-agent memory extraction."""

    # Same agent type mapping
    AGENT_TYPE_MAP = {
        "architect.md": "architect",
        "builder.md": "builder",
        "reviewer.md": "reviewer",
        "tester.md": "tester",
        "optimizer.md": "optimizer",
        "security.md": "security",
        "database.md": "database",
        "api-designer.md": "api-designer",
        "integration.md": "integration",
        "analyzer.md": "analyzer",
        "cleanup.md": "cleanup",
        "fix-agent.md": "fix-agent",
        "pre-commit-diagnostic.md": "pre-commit-diagnostic",
        "ci-diagnostic.md": "ci-diagnostic",
    }

    def __init__(self):
        super().__init__("post_agent")
        self.memory_enabled = self._check_memory_enabled()

    def _check_memory_enabled(self) -> bool:
        """Check if memory system is enabled."""
        config_file = self.project_root / ".claude" / "runtime" / "memory" / ".config"
        if not config_file.exists():
            return False

        import json
        try:
            with open(config_file) as f:
                config = json.load(f)
            return config.get("enabled", False)
        except Exception:
            return False

    def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract learnings from agent output and store.

        Args:
            input_data: {
                "agent_file": "architect.md",
                "task": "Design authentication system",
                "output": "Agent's full response text...",
                "duration_seconds": 45.2,
                "success": true,
                "task_category": "system_design"
            }

        Returns:
            {"memories_stored": 3, "memory_ids": [...]}
        """
        if not self.memory_enabled:
            return {}

        # Extract agent type
        agent_file = input_data.get("agent_file", "")
        agent_type = self.AGENT_TYPE_MAP.get(agent_file)

        if not agent_type:
            return {}

        # Extract agent output and metadata
        output = input_data.get("output", "")
        task = input_data.get("task", "")
        duration = input_data.get("duration_seconds", 0)
        success = input_data.get("success", True)
        task_category = input_data.get("task_category", "general")

        try:
            # Parse output for learnings
            learnings = self._extract_learnings(
                output=output,
                agent_type=agent_type,
                task_category=task_category
            )

            if not learnings:
                self.log(f"No learnings extracted from {agent_type} output", "DEBUG")
                return {}

            # Store memories
            memory_ids = self._store_memories(
                agent_type=agent_type,
                learnings=learnings,
                task=task,
                task_category=task_category,
                duration=duration,
                success=success
            )

            self.log(f"Stored {len(memory_ids)} memories from {agent_type}")
            self.save_metric("memories_stored", len(memory_ids))

            return {
                "memories_stored": len(memory_ids),
                "memory_ids": memory_ids
            }

        except Exception as e:
            self.log(f"Memory storage failed: {e}", "ERROR")
            return {}

    def _extract_learnings(
        self,
        output: str,
        agent_type: str,
        task_category: str
    ) -> List[Dict[str, Any]]:
        """Extract learnings from agent output using pattern matching."""
        learnings = []

        # Pattern 1: Explicit "Decision" sections (from DECISIONS.md format)
        decision_pattern = r"##\s+Decision\s+\d+:([^\n]+)\n\*\*What\*\*:([^\n]+)\n\*\*Why\*\*:([^\n]+)"
        for match in re.finditer(decision_pattern, output):
            learnings.append({
                "type": "decision",
                "content": f"{match.group(1).strip()}: {match.group(2).strip()}",
                "reasoning": match.group(3).strip(),
                "category": task_category,
                "confidence": 0.8
            })

        # Pattern 2: Recommendations/Key Points
        rec_pattern = r"(?:##\s+(?:Recommendation|Key Points?|Learnings?):?\s*\n)((?:[-*]\s+[^\n]+\n?)+)"
        for match in re.finditer(rec_pattern, output, re.IGNORECASE):
            items = re.findall(r"[-*]\s+([^\n]+)", match.group(1))
            for item in items:
                if len(item) > 20:  # Substantial content
                    learnings.append({
                        "type": "recommendation",
                        "content": item.strip(),
                        "category": task_category,
                        "confidence": 0.7
                    })

        # Pattern 3: Anti-patterns or Warnings
        warning_pattern = r"(?:âš ï¸|Warning|Caution|Anti-pattern|Avoid):?\s+([^\n]{20,})"
        for match in re.finditer(warning_pattern, output, re.IGNORECASE):
            learnings.append({
                "type": "anti_pattern",
                "content": match.group(1).strip(),
                "category": task_category,
                "confidence": 0.85  # High confidence for explicit warnings
            })

        # Pattern 4: Implementation patterns (for builder/implementer agents)
        if agent_type in ["builder", "architect"]:
            pattern_match = r"(?:Pattern|Approach|Solution):?\s+([^\n]{30,})"
            for match in re.finditer(pattern_match, output, re.IGNORECASE):
                learnings.append({
                    "type": "procedural",
                    "content": match.group(1).strip(),
                    "category": task_category,
                    "confidence": 0.75
                })

        # Pattern 5: Error solutions (for fix-agent, reviewer)
        if agent_type in ["fix-agent", "reviewer", "tester"]:
            error_pattern = r"(?:Error|Issue|Bug):([^\n]+)\n(?:Solution|Fix):([^\n]+)"
            for match in re.finditer(error_pattern, output, re.IGNORECASE):
                learnings.append({
                    "type": "error_solution",
                    "content": f"Error: {match.group(1).strip()} | Solution: {match.group(2).strip()}",
                    "category": "error_handling",
                    "confidence": 0.9
                })

        return learnings

    def _store_memories(
        self,
        agent_type: str,
        learnings: List[Dict[str, Any]],
        task: str,
        task_category: str,
        duration: float,
        success: bool
    ) -> List[str]:
        """Store extracted learnings in Neo4j."""
        try:
            ensure_neo4j_running(blocking=False)
            mgr = AgentMemoryManager(agent_type=agent_type)

            memory_ids = []
            for learning in learnings:
                # Determine if this should be global or project-scoped
                # High-confidence anti-patterns and error solutions are global
                is_global = (
                    learning["type"] in ["anti_pattern", "error_solution"]
                    and learning["confidence"] >= 0.85
                )

                # Convert learning type to memory type
                memory_type_map = {
                    "decision": "declarative",
                    "recommendation": "procedural",
                    "anti_pattern": "anti_pattern",
                    "procedural": "procedural",
                    "error_solution": "procedural"
                }
                memory_type = memory_type_map.get(learning["type"], "declarative")

                # Create memory with metadata
                memory_id = mgr.remember(
                    content=learning["content"],
                    category=learning.get("category", task_category),
                    memory_type=memory_type,
                    tags=[task_category, agent_type, learning["type"]],
                    confidence=learning["confidence"],
                    metadata={
                        "task": task[:200],  # Truncate
                        "duration_seconds": duration,
                        "success": success,
                        "reasoning": learning.get("reasoning", "")
                    },
                    global_scope=is_global
                )

                memory_ids.append(memory_id)

            return memory_ids

        except Exception as e:
            self.log(f"Neo4j storage error: {e}", "ERROR")
            return []


def main():
    """Entry point for post-agent hook."""
    hook = PostAgentHook()
    hook.run()


if __name__ == "__main__":
    main()
```

**Key Features**:

- Pattern-based extraction: No LLM calls needed
- Type-aware: Different patterns for different agent types
- Quality-aware: Confidence scoring for memories
- Scope-aware: High-confidence learnings become global
- Structured metadata: Duration, success, reasoning captured

---

### 2.3 Stop Hook Extension: Session Memory Consolidation

**Purpose**: Consolidate session-level learnings and index for future retrieval

**Location**: Extend existing `~/.amplihack/.claude/tools/amplihack/hooks/stop.py`

**Implementation**:

```python
# Add to existing stop.py after reflection trigger

def _consolidate_session_memories(self):
    """Consolidate session memories for faster future retrieval."""
    memory_enabled = self._check_memory_enabled()
    if not memory_enabled:
        return

    try:
        from amplihack.memory.neo4j.consolidation import SessionMemoryConsolidator

        session_id = self.get_session_id()
        consolidator = SessionMemoryConsolidator(session_id)

        # Identify high-value memories from this session
        summary = consolidator.consolidate()

        self.log(f"Session memory consolidation: {summary['memories_processed']} processed, "
                f"{summary['high_quality']} marked high-quality")

        self.save_metric("session_memories_consolidated", summary['memories_processed'])

    except Exception as e:
        self.log(f"Memory consolidation failed (non-critical): {e}", "WARNING")
```

---

### 2.4 Agent Invocation Integration

**Challenge**: How does the pre/post agent hook get triggered?

**Solution**: Extend the agent invocation mechanism

**Current Flow** (from codebase analysis):

```
User types: @architect design auth system
    â†“
Claude Code loads: .claude/agents/amplihack/core/architect.md
    â†“
Prompt constructed with agent definition + user task
    â†“
Agent executes
    â†“
Response returned
```

**New Flow with Memory Hooks**:

```
User types: @architect design auth system
    â†“
[Pre-Agent Hook] Query memories, format context
    â†“
Claude Code loads: architect.md
    â†“
Prompt = agent definition + user task + memory context
    â†“
Agent executes (with memory context)
    â†“
[Post-Agent Hook] Extract learnings, store in Neo4j
    â†“
Response returned
```

**Integration Method**: Session Start Hook Injection

```python
# In session_start.py, add memory system initialization

def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
    # ... existing code ...

    # Initialize memory system if enabled
    self._initialize_memory_system()

    # ... rest of existing code ...

def _initialize_memory_system(self):
    """Initialize memory system for this session."""
    memory_config = self.project_root / ".claude" / "runtime" / "memory" / ".config"
    if not memory_config.exists():
        # Create default config (disabled by default)
        memory_dir = self.project_root / ".claude" / "runtime" / "memory"
        memory_dir.mkdir(parents=True, exist_ok=True)

        import json
        with open(memory_config, "w") as f:
            json.dump({
                "enabled": False,  # Opt-in
                "auto_consolidate": True,
                "min_quality_threshold": 0.6,
                "max_context_memories": 10
            }, f, indent=2)

        self.log("Memory system config created (disabled by default)")
        return

    # If enabled, verify Neo4j is available
    import json
    with open(memory_config) as f:
        config = json.load(f)

    if config.get("enabled", False):
        try:
            from amplihack.memory.neo4j.lifecycle import ensure_neo4j_running
            ensure_neo4j_running(blocking=False)
            self.log("Memory system initialized")
        except Exception as e:
            self.log(f"Memory system unavailable: {e}", "WARNING")
```

---

## 3. Memory Context Injection Format

### 3.1 What Agents See

When an agent is invoked with memory enabled, their prompt includes:

```markdown
## ðŸ§  Memory Context (Relevant Past Learnings)

### Past Architect Agent Learnings

**1. system_design** (quality: 0.85)
Always separate authentication from authorization logic
_Outcome: Reduced coupling, easier testing_

**2. api_design** (quality: 0.78)
Use token-based auth for stateless APIs
_Outcome: Better scalability_

**3. error_handling** (quality: 0.72)
Implement circuit breaker pattern for external auth services
_Outcome: Improved resilience_

### Learnings from Other Agents

**1. From builder**: error_handling
Auth token validation must happen before business logic

**2. From reviewer**: security
Never log authentication tokens, even in debug mode

---

[Normal agent prompt continues here...]

You are the system architect who embodies ruthless simplicity...
```

### 3.2 Context Size Management

**Problem**: Memory context could bloat prompts

**Solution**: Quality-based filtering + limits

```python
# In pre_agent.py
def _query_memories(self, agent_type: str, task: str, task_category: Optional[str]) -> Dict:
    memories = mgr.recall(
        category=task_category,
        min_quality=0.6,  # Only quality memories
        include_global=True,
        limit=10  # Hard cap on count
    )

    # Additional filtering by relevance
    relevant_memories = [
        m for m in memories
        if self._is_relevant(m, task)
    ][:5]  # Top 5 most relevant

    return relevant_memories
```

**Estimated Context Size**:

- 5 memories Ã— 100 chars avg = 500 chars
- 3 cross-agent learnings Ã— 80 chars = 240 chars
- Formatting overhead = 200 chars
- **Total: ~1000 chars per agent invocation**

This is acceptable overhead (< 1% of typical prompts).

---

## 4. Memory Extraction Patterns

### 4.1 What Constitutes a "Memory"?

**Include**:

- âœ… Explicit decisions with reasoning
- âœ… Patterns that worked well
- âœ… Anti-patterns or warnings
- âœ… Error-solution pairs
- âœ… Design trade-offs
- âœ… Performance insights

**Exclude**:

- âŒ Routine status updates
- âŒ File listings
- âŒ Test output
- âŒ Generic statements
- âŒ Temporary context

### 4.2 Extraction Quality Criteria

```python
def _assess_learning_quality(self, learning: Dict) -> float:
    """Assess quality of extracted learning (0-1)."""
    score = 0.5  # Base score

    # Has reasoning/explanation: +0.2
    if learning.get("reasoning"):
        score += 0.2

    # Has outcome/result: +0.15
    if learning.get("metadata", {}).get("outcome"):
        score += 0.15

    # Has concrete examples: +0.1
    if any(marker in learning["content"] for marker in ["example:", "e.g.", "for instance"]):
        score += 0.1

    # Is anti-pattern (high value): +0.2
    if learning["type"] == "anti_pattern":
        score += 0.2

    # Agent succeeded in task: +0.1
    if learning.get("success", False):
        score += 0.1

    return min(score, 1.0)
```

### 4.3 Agent-Specific Extraction

Different agents produce different learnings:

**Architect**:

- Design decisions and rationale
- Architecture patterns
- Trade-off analysis
- Module specifications

**Builder**:

- Implementation patterns
- Code structure decisions
- Library choices
- Refactoring strategies

**Reviewer**:

- Common mistakes found
- Philosophy violations
- Code quality issues
- Best practice violations

**Tester**:

- Test strategies that worked
- Edge cases discovered
- Test data patterns
- Coverage approaches

**Fix-Agent**:

- Error patterns and solutions
- Root cause analysis
- Prevention strategies
- Diagnostic approaches

---

## 5. Non-Invasive Integration Guarantees

### 5.1 What Agents DON'T Need to Change

**Agent Markdown Files**: Zero modifications required

```markdown
# architect.md stays exactly the same

---

name: architect
description: Primary architecture and design agent

---

# Architect Agent

You are the system architect...
```

**Agent Invocation**: Same syntax

```
User: @architect design auth system
â†’ Works exactly as before, but now with memory context
```

**Agent Output**: No format changes required

```
Agents output whatever they want
â†’ Post-hook extracts learnings automatically
```

### 5.2 Opt-In Mechanism

**Default**: Memory system disabled

**Enable**: Create/edit `~/.amplihack/.claude/runtime/memory/.config`

```json
{
  "enabled": true,
  "auto_consolidate": true,
  "min_quality_threshold": 0.6,
  "max_context_memories": 10,
  "agent_whitelist": ["architect", "builder", "reviewer"] // optional
}
```

**Disable**: Set `"enabled": false` or delete config

### 5.3 Fallback Behavior

**If Neo4j unavailable**:

- Pre-agent hook: Skip memory loading, log warning
- Post-agent hook: Skip memory storage, log warning
- Agents continue working normally

**If memory query fails**:

- Pre-agent hook: Return empty context
- Agent receives no memory context (business as usual)

**If memory storage fails**:

- Post-agent hook: Log error, continue
- Agent output returned normally

**Principle**: Memory system NEVER breaks agent execution

---

## 6. Value Proposition: Why Agents Should Use Memory

### 6.1 Architect Agent Benefits

**Before Memory**:

```
User: Design authentication system
Architect: Analyzes from scratch every time
â†’ Reinvents patterns already used
â†’ May repeat past mistakes
```

**With Memory**:

```
User: Design authentication system
Architect: Sees we've designed 3 auth systems before
â†’ "We used token-based auth successfully 2 times"
â†’ "Watch out for X issue we encountered before"
â†’ Faster, more consistent designs
```

**Measurable Impact**:

- 30% faster design phase (no reinvention)
- 50% fewer repeated mistakes
- Consistent patterns across projects

### 6.2 Builder Agent Benefits

**Before Memory**:

```
User: Implement user registration
Builder: Implements from spec
â†’ May use inconsistent patterns
â†’ Duplicates code from other features
```

**With Memory**:

```
User: Implement user registration
Builder: Sees similar implementation patterns
â†’ "We implemented similar validation 5 times, here's the template"
â†’ "Previous implementations had X bug, avoid it"
â†’ Faster implementation, consistent style
```

**Measurable Impact**:

- 40% faster implementation (templates)
- 70% reduction in repeated bugs
- More consistent codebase

### 6.3 Reviewer Agent Benefits

**Before Memory**:

```
Reviewer: Checks code against philosophy
â†’ Finds issues based on current knowledge only
â†’ May miss patterns from past reviews
```

**With Memory**:

```
Reviewer: Checks code + memory of past issues
â†’ "This pattern caused problems in PR #123"
â†’ "We agreed to avoid X approach last month"
â†’ More comprehensive reviews
```

**Measurable Impact**:

- 25% more issues caught
- Consistent enforcement of learnings
- Institutional knowledge preserved

### 6.4 Fix-Agent Benefits

**Before Memory**:

```
User: Tests failing
Fix-Agent: Diagnoses from scratch
â†’ May try solutions that failed before
â†’ Slower root cause analysis
```

**With Memory**:

```
User: Tests failing
Fix-Agent: Queries error history
â†’ "We've seen this error 3 times, root cause was X"
â†’ "Solution Y worked in 2/3 cases"
â†’ Instant fix from template
```

**Measurable Impact**:

- 60% faster fixes (known errors)
- 80% reduction in fix iteration cycles
- Better root cause identification

---

## 7. Implementation Roadmap

### Phase 1: Hook Infrastructure (2-3 hours)

**Tasks**:

1. Create `pre_agent.py` hook
2. Create `post_agent.py` hook
3. Extend `stop.py` with consolidation
4. Add memory initialization to `session_start.py`
5. Create `~/.amplihack/.claude/runtime/memory/.config` default

**Deliverables**:

- Hooks operational but disabled by default
- Config file creation on first session
- Memory system opt-in ready

**Testing**:

```bash
# Test hook execution
python .claude/tools/amplihack/hooks/pre_agent.py < test_input.json

# Verify hook registration
ls -la .claude/tools/amplihack/hooks/
```

### Phase 2: Agent Type Detection (1-2 hours)

**Tasks**:

1. Implement agent filename â†’ type mapping
2. Add task category detection logic
3. Test with all agent types

**Testing**:

```python
# Test agent detection
assert PreAgentHook.AGENT_TYPE_MAP["architect.md"] == "architect"

# Test task category detection
assert _detect_task_category("design auth system") == "system_design"
```

### Phase 3: Memory Query Integration (2-3 hours)

**Tasks**:

1. Implement `_query_memories()` in pre-agent hook
2. Add relevance filtering
3. Implement context formatting
4. Add quality thresholds

**Testing**:

```python
# Test memory query
memories = pre_agent._query_memories(
    agent_type="architect",
    task="design auth",
    task_category="system_design"
)
assert len(memories) <= 10  # Respects limit
assert all(m["quality_score"] >= 0.6 for m in memories)  # Quality filter
```

### Phase 4: Memory Extraction Integration (3-4 hours)

**Tasks**:

1. Implement pattern-based extraction in post-agent hook
2. Add agent-specific extraction logic
3. Implement quality assessment
4. Add metadata capture

**Testing**:

```python
# Test learning extraction
output = "## Decision: Use JWT\n**What**: Token-based auth\n**Why**: Stateless"
learnings = post_agent._extract_learnings(output, "architect", "system_design")
assert len(learnings) > 0
assert learnings[0]["type"] == "decision"
```

### Phase 5: End-to-End Testing (2-3 hours)

**Tasks**:

1. Test full agent invocation flow with memory
2. Verify memory appears in agent context
3. Verify learnings stored in Neo4j
4. Test fallback behavior (Neo4j down)

**Test Scenario**:

```bash
# Enable memory
echo '{"enabled": true}' > .claude/runtime/memory/.config

# Invoke architect agent
# @architect design authentication system

# Verify memory context injected (check logs)
grep "Memory Context" .claude/runtime/logs/*/session.log

# Invoke architect again on similar task
# @architect design authorization system

# Verify previous learnings appear in context
# Should see "Past Architect Agent Learnings" section
```

### Phase 6: Documentation & Handoff (1-2 hours)

**Tasks**:

1. Document enabling memory system
2. Create troubleshooting guide
3. Add metrics/monitoring guide
4. Document memory CLI commands

**Deliverables**:

- `docs/MEMORY_AGENT_INTEGRATION.md`
- `docs/MEMORY_TROUBLESHOOTING.md`
- CLI: `amplihack memory status`
- CLI: `amplihack memory query <agent> <category>`

---

## 8. Monitoring & Observability

### 8.1 Metrics Tracked

**Hook-Level Metrics** (via HookProcessor):

```
memories_loaded: Count per agent invocation
memories_stored: Count per agent completion
memory_query_time_ms: Query latency
memory_storage_time_ms: Storage latency
memory_query_failures: Failed queries
memory_storage_failures: Failed stores
```

**Session-Level Metrics**:

```
session_memories_total: Total memories this session
session_memories_high_quality: High-quality count
session_memories_global: Global-scope memories
session_agents_with_memory: Agents that used memory
```

**System-Level Metrics** (Neo4j):

```
total_memories: Total in database
memories_by_agent_type: Breakdown by agent
memories_by_category: Breakdown by category
avg_memory_quality: Average quality score
memory_reuse_rate: How often memories are recalled
```

### 8.2 Observability Tools

**CLI Commands**:

```bash
# System status
amplihack memory status
# Output: Neo4j: running, Memories: 1,234, Avg Quality: 0.73

# Agent memory stats
amplihack memory stats architect
# Output: Architect memories: 156, Avg quality: 0.78, Most used category: system_design

# Query memories
amplihack memory query architect system_design --limit 5
# Output: Top 5 architect memories for system_design

# Session memory report
amplihack memory session-report
# Output: This session: 12 memories stored, 8 high-quality, 3 global
```

**Log Analysis**:

```bash
# Check memory integration
grep "Memory Context" .claude/runtime/logs/*/session.log

# Check memory storage
grep "memories stored" .claude/runtime/logs/*/session.log

# Check failures
grep -i "memory.*error" .claude/runtime/logs/*/session.log
```

---

## 9. Example: Architect Agent with Memory

### 9.1 First Invocation (No Memories)

**User**: @architect design user authentication system

**Pre-Agent Hook**:

```
Query Neo4j for architect + system_design memories
â†’ No matching memories found (first time)
â†’ Agent receives no memory context
```

**Agent Prompt**:

```markdown
# Architect Agent

You are the system architect who embodies ruthless simplicity...

[Task]: Design user authentication system

[Agent proceeds with fresh analysis]
```

**Agent Output**:

```markdown
## Authentication System Design

### Decision 1: Token-Based Authentication

**What**: Use JWT tokens for stateless authentication
**Why**: Enables horizontal scaling, reduces server state
**Trade-offs**: Requires secure token storage on client

### Decision 2: Separate Auth Service

**What**: Dedicated microservice for authentication
**Why**: Single responsibility, easier to secure
**Trade-offs**: Additional network hop

### Recommendation:

- Use bcrypt for password hashing
- Implement refresh token rotation
- Add rate limiting on auth endpoints
```

**Post-Agent Hook**:

```
Extract learnings from output:
1. Decision: Token-based auth (JWT) â†’ quality: 0.85
2. Decision: Separate auth service â†’ quality: 0.82
3. Recommendation: bcrypt + refresh rotation â†’ quality: 0.78

Store 3 memories in Neo4j:
- memory_001: "Use JWT for stateless auth" (architect, system_design, global)
- memory_002: "Separate auth service for security" (architect, system_design)
- memory_003: "Implement refresh token rotation" (architect, security, global)
```

### 9.2 Second Invocation (With Memories)

**User**: @architect design authorization system for resource access

**Pre-Agent Hook**:

```
Query Neo4j for architect + system_design memories
â†’ Found 3 relevant memories from previous auth work
â†’ Format memory context
```

**Agent Prompt**:

```markdown
## ðŸ§  Memory Context (Relevant Past Learnings)

### Past Architect Agent Learnings

**1. system_design** (quality: 0.85)
Use JWT tokens for stateless authentication
_Outcome: Enabled horizontal scaling_

**2. system_design** (quality: 0.82)
Separate auth service for single responsibility
_Outcome: Easier to secure and maintain_

**3. security** (quality: 0.78)
Implement refresh token rotation for security
_Outcome: Reduced token theft risk_

---

# Architect Agent

You are the system architect who embodies ruthless simplicity...

[Task]: Design authorization system for resource access

[Agent can now leverage past learnings]
```

**Agent Output**:

```markdown
## Authorization System Design

### Building on Previous Auth Design

Based on our previous authentication system design, I'll integrate authorization seamlessly.

### Decision 1: Embed Permissions in JWT Claims

**What**: Include user roles/permissions in JWT payload
**Why**: Leverages existing token-based auth, stateless authorization
**Why Not Separate**: Reduces latency, avoids extra service calls

### Decision 2: Resource-Based Access Control (RBAC)

**What**: Permission model tied to resources and actions
**Why**: Flexible, scalable, aligns with microservices
**Trade-offs**: More complex than role-only approach

### Integration Points:

- Auth service generates JWTs with permission claims
- Each microservice validates permissions locally
- Refresh token rotation (from previous design) includes updated permissions
```

**Post-Agent Hook**:

```
Extract learnings:
1. Decision: Embed permissions in JWT â†’ quality: 0.83
2. Decision: Resource-based access control â†’ quality: 0.80
3. Integration: JWT claims for authorization â†’ quality: 0.78

Store 3 new memories:
- memory_004: "Embed permissions in JWT claims for stateless authz" (architect, system_design)
- memory_005: "Use RBAC for resource access control" (architect, system_design)
- memory_006: "Integrate authz with existing JWT auth" (architect, integration)

Update memory_001 usage_count (was recalled) â†’ increases quality score
```

**Result**: Second design is faster, more consistent, and builds on previous learnings.

---

## 10. Security & Privacy Considerations

### 10.1 Sensitive Data Protection

**Problem**: Agent outputs may contain sensitive information

**Mitigation**:

```python
# In post_agent.py
def _sanitize_content(self, content: str) -> str:
    """Remove sensitive data before storage."""
    # Pattern-based redaction
    content = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '[EMAIL]', content)
    content = re.sub(r'\b(?:\d{4}[-\s]?){3}\d{4}\b', '[CARD]', content)
    content = re.sub(r'\b[A-Za-z0-9]{20,}\b', '[TOKEN]', content)  # Long alphanumeric strings

    # Additional redaction patterns...
    return content
```

**Additional Layer**: XPIA defense integration

- Memory content passes through XPIA scanner before storage
- High-risk content flagged or rejected

### 10.2 Memory Access Control

**Scope Isolation**:

```
Global memories: Available to all projects
Project memories: Scoped to project_id
Session memories: Scoped to session_id (short-lived)
```

**Agent Permissions**:

```python
# Only certain agents can create global memories
GLOBAL_MEMORY_AGENTS = ["architect", "security", "reviewer"]

if agent_type not in GLOBAL_MEMORY_AGENTS:
    # Force project scope
    global_scope = False
```

### 10.3 Memory Expiration

**Automatic Cleanup**:

```python
# In consolidation phase
def _expire_old_memories(self):
    """Remove stale low-quality memories."""
    # Memories expire based on:
    # - Age (>90 days) + low quality (<0.5)
    # - Never used (usage_count = 0) + age >60 days
    # - Superseded by newer, better memories
```

---

## 11. Success Criteria

### 11.1 Technical Success

âœ… **Hooks Operational**:

- Pre-agent hook loads memories in <100ms (p95)
- Post-agent hook stores learnings in <200ms (p95)
- Stop hook consolidates session in <500ms

âœ… **Memory Quality**:

- Average memory quality >0.70
- <5% of memories flagged as low-quality
- 80%+ of memories have metadata

âœ… **Non-Invasive**:

- Zero agent markdown file changes
- No breaking changes to existing workflows
- Fallback to no-memory mode on failures

### 11.2 User Experience Success

âœ… **Faster Iterations**:

- 30% reduction in time for similar tasks
- 50% fewer repeated mistakes
- Measurable improvement in agent consistency

âœ… **Opt-In Adoption**:

- Easy enable: edit one config file
- Clear documentation
- No performance degradation when disabled

âœ… **Transparency**:

- Users can see what memories agents use
- CLI tools for memory inspection
- Clear logging of memory operations

### 11.3 Agent Effectiveness Success

After 1 month of usage:

- 80%+ of agent invocations use relevant memories
- 60%+ of agents contribute new learnings
- Memory reuse rate >50% (memories recalled multiple times)

---

## 12. Risks & Mitigations

### Risk 1: Memory Context Bloat

**Impact**: Agent prompts become too large
**Mitigation**: Hard limits (10 memories max), quality filtering (>0.6), relevance scoring

### Risk 2: Low-Quality Memories

**Impact**: Agents get bad advice from past mistakes
**Mitigation**: Quality assessment, confidence scoring, periodic cleanup, user feedback

### Risk 3: Neo4j Unavailability

**Impact**: Memory system breaks agent execution
**Mitigation**: Non-blocking initialization, fallback to no-memory mode, graceful degradation

### Risk 4: Privacy Leaks

**Impact**: Sensitive data stored in memories
**Mitigation**: Content sanitization, XPIA integration, scope isolation, expiration policies

### Risk 5: Performance Overhead

**Impact**: Memory queries slow down agents
**Mitigation**: Async queries, connection pooling, caching, query limits

---

## 13. Future Enhancements

### 13.1 Cross-Project Learning

Enable agents to learn from other projects (with user consent):

```python
# Query memories across all projects
cross_project_memories = mgr.recall(
    category=task_category,
    scope="global",
    include_cross_project=True  # NEW
)
```

### 13.2 Memory Quality Feedback Loop

Allow agents to rate memory usefulness:

```python
# Agent reports: "This memory was helpful/not helpful"
mgr.rate_memory(memory_id, usefulness=0.9)
# Adjusts quality score over time
```

### 13.3 Memory Visualization

Build UI for exploring memory graph:

```
http://localhost:7474
â†’ Neo4j browser with custom queries
â†’ See agent learning networks
â†’ Identify knowledge gaps
```

### 13.4 Semantic Memory Search

Upgrade from keyword-based to embedding-based search:

```python
# Use vector similarity for better relevance
memories = mgr.recall_semantic(
    task_description="design auth system",
    top_k=5
)
```

---

## 14. Conclusion

This design achieves **zero-modification agent integration** by:

1. Extending existing hook infrastructure (session_start, stop, pre/post agent)
2. Using pattern-based learning extraction (no LLM overhead)
3. Providing opt-in, non-invasive memory context injection
4. Ensuring graceful fallback on failures

**Agents gain memory capabilities automatically** without awareness, just like humans learn from experience without explicit instruction.

**Next Steps**:

1. Review and approve this design
2. Implement Phase 1 (hook infrastructure)
3. Test with single agent type (architect)
4. Expand to all agents
5. Monitor and iterate based on usage

**Estimated Total Implementation Time**: 12-15 hours across 6 phases.
