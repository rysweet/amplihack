# Azure OpenAI Configuration for amplihack launch --with-proxy-config
# Copy this file and replace with your actual Azure OpenAI credentials

# Required: Your Azure OpenAI API key
OPENAI_API_KEY="YOUR_AZURE_OPENAI_KEY_HERE"  # pragma: allowlist secret

# Required: Azure OpenAI endpoint URL
# Format: https://<resource-name>.openai.azure.com/openai/deployments/<deployment-name>/chat/completions?api-version=<version>
OPENAI_BASE_URL="https://your-resource.openai.azure.com/openai/deployments/gpt-4/chat/completions?api-version=2025-01-01-preview"

# Required: Azure-specific settings
AZURE_OPENAI_KEY="YOUR_AZURE_OPENAI_KEY_HERE"  # pragma: allowlist secret
AZURE_API_VERSION="2025-01-01-preview"

# Model mappings - adjust to your Azure deployment names
# Maps to Claude's largest model
BIG_MODEL="gpt-4"
# Maps to Claude's mid-tier model
MIDDLE_MODEL="gpt-4"
# Maps to Claude's smallest/fastest model
SMALL_MODEL="gpt-4-turbo"

# Optional: Expected Anthropic API key for client validation
# Uncomment and set if you want to require a specific key from Claude Code
# ANTHROPIC_API_KEY="YOUR_ANTHROPIC_API_KEY_HERE"  # pragma: allowlist secret

# Server settings
# Use localhost for security
HOST="127.0.0.1"
PORT="8082"
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL="INFO"

# Performance settings - optimized for large context
# 512k tokens - maximum context size
MAX_TOKENS_LIMIT="512000"
# Minimum tokens (to avoid errors with thinking model)
MIN_TOKENS_LIMIT="4096"
# 5 minutes for large requests
REQUEST_TIMEOUT="300"
# Retry on transient failures
MAX_RETRIES="2"

# Alternative Azure configurations (commented examples):

# Example 1: Azure OpenAI in East US 2
# OPENAI_BASE_URL="https://my-oai-eastus2.openai.azure.com/openai/deployments/gpt-4-turbo/chat/completions?api-version=2025-01-01-preview"
# BIG_MODEL="gpt-4-turbo"
# MIDDLE_MODEL="gpt-4-turbo"
# SMALL_MODEL="gpt-4-turbo"

# Example 2: Azure OpenAI with GPT-4o
# OPENAI_BASE_URL="https://my-resource.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview"
# BIG_MODEL="gpt-4o"
# MIDDLE_MODEL="gpt-4o"
# SMALL_MODEL="gpt-4o-mini"

# Notes:
# 1. Replace all placeholder values with your actual Azure credentials
# 2. The deployment name in OPENAI_BASE_URL must match your Azure deployment
# 3. MAX_TOKENS_LIMIT is set to 512k for maximum context window
# 4. When using with amplihack, the Azure persistence prompt is automatically included
# 5. For troubleshooting, set LOG_LEVEL="DEBUG"
