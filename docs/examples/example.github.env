# GitHub Copilot Configuration
# Copy this file to .github.env and edit with your credentials

# Required: GitHub token with Copilot access
GITHUB_TOKEN=YOUR_GITHUB_TOKEN_HERE  # pragma: allowlist secret

# Enable GitHub Copilot proxy mode
GITHUB_COPILOT_ENABLED=true
PROXY_TYPE=github_copilot

# Enable LiteLLM GitHub Copilot provider integration
GITHUB_COPILOT_LITELLM_ENABLED=true

# Optional: Specify default GitHub Copilot model
GITHUB_COPILOT_MODEL=copilot-gpt-4

# Optional: GitHub Copilot endpoint (defaults to api.github.com)
# GITHUB_COPILOT_ENDPOINT=https://api.github.com/copilot

# Proxy server settings
PORT=8080
HOST=localhost

# Performance settings
REQUEST_TIMEOUT=300
MAX_RETRIES=3
LOG_LEVEL=INFO

# Optional: Model mappings (OpenAI model -> GitHub Copilot model)
# GITHUB_COPILOT_GPT_4_MODEL=copilot-gpt-4
# GITHUB_COPILOT_GPT_3_5_TURBO_MODEL=copilot-gpt-3.5-turbo

# Optional: Rate limiting (GitHub Copilot has built-in limits)
MAX_TOKENS_LIMIT=8192
